{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Letters.png\" width=324 height=332 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "burti = [\n",
    "    ['A',[0,1,0,1,0,1,1,1,1,1,0,1,1,0,1],[1,0,0]],\n",
    "    ['E',[1,1,1,1,0,0,1,1,0,1,0,0,1,1,1],[1,0,0]],\n",
    "    ['D',[1,1,0,1,0,1,1,0,1,1,0,1,1,1,0],[1,0,0]],\n",
    "    ['B',[1,1,0,1,0,1,1,1,0,1,0,1,1,1,0],[0,1,0]],\n",
    "    ['C',[1,1,1,1,0,0,1,0,0,1,0,0,1,1,1],[0,1,0]],\n",
    "    ['F',[1,1,1,1,0,0,1,1,0,1,0,0,1,0,0],[0,1,0]],\n",
    "    ['G',[1,1,1,1,0,0,1,0,1,1,0,1,1,1,1],[0,0,1]],\n",
    "    ['H',[1,0,1,1,0,1,1,1,1,1,0,1,1,0,1],[0,0,1]],\n",
    "    ['I',[0,1,0,0,1,0,0,1,0,0,1,0,0,1,0],[0,0,1]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', [0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1], [1, 0, 0]], ['E', [1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1], [1, 0, 0]], ['D', [1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0], [1, 0, 0]], ['B', [1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0], [0, 1, 0]], ['C', [1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], [0, 1, 0]], ['F', [1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0], [0, 1, 0]], ['G', [1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1], [0, 0, 1]], ['H', [1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1], [0, 0, 1]], ['I', [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0], [0, 0, 1]]]\n"
     ]
    }
   ],
   "source": [
    "print(burti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lc = 0.1  #Apmācības koeficients\n",
    "\n",
    "class Neirons:\n",
    "    \n",
    "    def __init__(self, inSize):\n",
    "        self.w = np.zeros(inSize)\n",
    "        self.w0 = 0\n",
    "    \n",
    "    def classify(self, x):\n",
    "        net = np.dot(x, self.w)\n",
    "        net += self.w0\n",
    "        y = 0 if net < 0 else 1\n",
    "        return y\n",
    "    \n",
    "    def learn(self, x, z):\n",
    "        y = self.classify(x)\n",
    "        delta = z-y\n",
    "        if delta != 0:\n",
    "            for i in range(0, len(self.w)):\n",
    "                self.w[i]+= lc * delta * x[i]\n",
    "            self.w0+= lc * delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 1 0 0\n",
      "E 1 0 0\n",
      "D 1 0 0\n",
      "B 0 1 0\n",
      "C 0 1 0\n",
      "F 0 1 0\n",
      "G 0 0 1\n",
      "H 0 0 1\n",
      "I 0 0 1\n"
     ]
    }
   ],
   "source": [
    "n1 = Neirons(15);\n",
    "n2 = Neirons(15);\n",
    "n3 = Neirons(15);\n",
    "# print(n1.classify(burti[0][1]))\n",
    "\n",
    "for eph in range(0, 100):\n",
    "    for bi in range(0, len(burti)):\n",
    "        n1.learn(burti[bi][1], burti[bi][2][0])\n",
    "        n2.learn(burti[bi][1], burti[bi][2][1])\n",
    "        n3.learn(burti[bi][1], burti[bi][2][2])\n",
    "\n",
    "for bi in range(0, len(burti)):\n",
    "    print(\n",
    "        burti[bi][0]+\" \"\n",
    "        +str(n1.classify(burti[bi][1]))+\" \"\n",
    "        +str(n2.classify(burti[bi][1]))+\" \"\n",
    "        +str(n3.classify(burti[bi][1]))\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6  0.4 -0.7  0.  -0.5 -0.2  0.   0.9  1.8  0.  -0.5 -1.1  0.   0.2\n",
      "  0.3]\n",
      "[ 0.3  0.  -0.3  0.2 -0.3  0.4  0.2 -0.4 -1.4  0.2 -0.3 -0.1  0.2  0.1\n",
      " -0.4]\n",
      "[ 0.2 -0.3  0.3 -0.2  0.3 -0.1 -0.2 -0.2  0.4 -0.2  0.3  0.4 -0.2  0.1\n",
      " -0.1]\n"
     ]
    }
   ],
   "source": [
    "print(n1.w)\n",
    "print(n2.w)\n",
    "print(n3.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "print(iris)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3019\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2778\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2613\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2471\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2350\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2249\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2163\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2093\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2037\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1993\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1959\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1933\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1914\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1901\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1891\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1883\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1878\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1873\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1867\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1863\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1857\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.1853\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1849\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1845\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1841\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1837\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1833\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1830\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1827\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1823\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.1820\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1818\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1814\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1813\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1810\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1808\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1806\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1803\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1801\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1799\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.1798\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1795\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1794\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1792\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1790\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1789\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1787\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.1787\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1784\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1783\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1782\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 956us/step - loss: 0.1780\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1779\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1778\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1778\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1776\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1775\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1774\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1773\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1772\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1772\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1770\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1770\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1769\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1768\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1768\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1767\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1767\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1766\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1765\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1765\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1765\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1764\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1763\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1764\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1762\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 848us/step - loss: 0.1762\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1762\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1762\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 839us/step - loss: 0.1761\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1761\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1760\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1759\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1760\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1759\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1759\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1759\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 829us/step - loss: 0.1758\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1757\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1757\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1757\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1757\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1756\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1756\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1756\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1755\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1755\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1755\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1755\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1754\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1754\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1755\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1753\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1753\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1753\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1753\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1753\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1752\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1753\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1753\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1752\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 804us/step - loss: 0.1752\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 992us/step - loss: 0.1751\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1751\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1751\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1751\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1751\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1750\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1751\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1750\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1750\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1749\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1750\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1749\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1750\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.1749\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1748\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1749\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1748\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1748\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.1748\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1748\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1748\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1748\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1747\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1747\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1747\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1748\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1747\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1747\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1746\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.1746\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 965us/step - loss: 0.1746\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1746\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1746\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1746\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1747\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1746\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 986us/step - loss: 0.1745\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1745\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1745\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1746\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1745\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1745\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1746\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1744\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1745\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1744\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1744\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1744\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1744\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1744\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1745\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1744\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1744\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1743\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1744\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1743\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1743\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1744\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1743\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.1743\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1743\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1743\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1743\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1743\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1742\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1742\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1742\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1742\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 837us/step - loss: 0.1742\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.1742\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1742\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1742\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1742\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 869us/step - loss: 0.1741\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1742\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1741\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1741\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1741\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1741\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1740\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1741\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1740\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 858us/step - loss: 0.1740\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1740\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1740\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1739\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1739\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1739\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1739\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1739\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1738\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1739\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1739\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.1738\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1738\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1737\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1737\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 917us/step - loss: 0.1737\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1736\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1736\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1735\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1735\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1734\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1734\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 990us/step - loss: 0.1733\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1733\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1732\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1731\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1731\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1730\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1730\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1728\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1727\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1726\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1726\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1724\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1722\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1721\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1720\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1718\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1716\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1714\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1712\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1709\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1707\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1704\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1700\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1696\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1692\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1687\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1681\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1675\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1669\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1661\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1653\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1643\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1633\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1622\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1609\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1595\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1579\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1560\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1539\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1517\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1493\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1467\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1440\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1414\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1387\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1357\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1329\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1303\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1278\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1257\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1236\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1218\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1198\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1183\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1170\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1155\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1142\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1128\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1116\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1106\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1093\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1082\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1070\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1059\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1048\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1038\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1029\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1019\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1010\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1001\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0992\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0984\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0975\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0967\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0958\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0951\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0946\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0937\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0931\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0925\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0916\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0910\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0902\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0894\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#  from keras.layers import Dense\n",
    "#  from keras.models import Sequential\n",
    "\n",
    "model = tf.keras.models.Sequential()  #izveidot tukšu modeli\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(3, activation='softmax', input_shape = (len(iris.data[0]), ))\n",
    ")  #Pievienot vienu slāni ar 3 neironiem, \"softmax\" aktivācijas funkciju un norādot ieejas signāla garumu (4)\n",
    "\n",
    "model.compile(tf.optimizers.RMSprop(0.001), loss='mse')  #Pabeigt modeļa izveidi.\n",
    "# Izmatot optimizatoru RMSprop ar apmācības ātrumu 0,001.\n",
    "# Izmantot vidējo kvadrātisko kļūdu.\n",
    "\n",
    "# Izveidot jaunu \"pareizo\" vērtību masīvu no iris masīva, nomainot saturu no [0,1,2...] uz [[1,0,0],[0,1,0],[0,0,1]..]\n",
    "targets = np.zeros((len(iris.target),3))  #Izveidot 150x3 lielu masīvu un aizpildīt ar nullēm\n",
    "for ti in range(0, len(iris.target)):\n",
    "    if iris.target[ti] == 0:\n",
    "        targets[ti][0] = 1\n",
    "    elif iris.target[ti] == 1:\n",
    "        targets[ti][1] = 1\n",
    "    else:\n",
    "        targets[ti][2] = 1\n",
    "print(targets)\n",
    "print(iris.data)\n",
    "model.fit(iris.data, targets, epochs=300)  #Veikt apmācību\n",
    "\n",
    "predictions = model.predict(iris.data)  #Iegū klašu piederības vērtības datiem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1\t3.5\t1.4\t0.2\t1.0\t0.0\t0.0\t0.8774406\t0.1225593\t1.0287184e-07\n",
      "4.9\t3.0\t1.4\t0.2\t1.0\t0.0\t0.0\t0.8214842\t0.17851548\t3.131519e-07\n",
      "4.7\t3.2\t1.3\t0.2\t1.0\t0.0\t0.0\t0.8536941\t0.14630562\t3.4332362e-07\n",
      "4.6\t3.1\t1.5\t0.2\t1.0\t0.0\t0.0\t0.80916023\t0.19083938\t3.8068464e-07\n",
      "5.0\t3.6\t1.4\t0.2\t1.0\t0.0\t0.0\t0.88412184\t0.115878046\t1.01961454e-07\n",
      "5.4\t3.9\t1.7\t0.4\t1.0\t0.0\t0.0\t0.8961626\t0.10383744\t1.910517e-08\n",
      "4.6\t3.4\t1.4\t0.3\t1.0\t0.0\t0.0\t0.8662486\t0.1337512\t2.2949446e-07\n",
      "5.0\t3.4\t1.5\t0.2\t1.0\t0.0\t0.0\t0.85311645\t0.14688338\t1.2757684e-07\n",
      "4.4\t2.9\t1.4\t0.2\t1.0\t0.0\t0.0\t0.795224\t0.20477527\t7.8896545e-07\n",
      "4.9\t3.1\t1.5\t0.1\t1.0\t0.0\t0.0\t0.80660546\t0.19339423\t2.731646e-07\n",
      "5.4\t3.7\t1.5\t0.2\t1.0\t0.0\t0.0\t0.8883453\t0.11165469\t4.2225977e-08\n",
      "4.8\t3.4\t1.6\t0.2\t1.0\t0.0\t0.0\t0.8339301\t0.16606967\t1.564671e-07\n",
      "4.8\t3.0\t1.4\t0.1\t1.0\t0.0\t0.0\t0.80833876\t0.1916609\t4.1510145e-07\n",
      "4.3\t3.0\t1.1\t0.1\t1.0\t0.0\t0.0\t0.8430769\t0.15692197\t1.2283176e-06\n",
      "5.8\t4.0\t1.2\t0.2\t1.0\t0.0\t0.0\t0.93814445\t0.06185559\t1.8372491e-08\n",
      "5.7\t4.4\t1.5\t0.4\t1.0\t0.0\t0.0\t0.9445517\t0.05544831\t6.294806e-09\n",
      "5.4\t3.9\t1.3\t0.4\t1.0\t0.0\t0.0\t0.93059784\t0.069402196\t2.803825e-08\n",
      "5.1\t3.5\t1.4\t0.3\t1.0\t0.0\t0.0\t0.8847209\t0.11527892\t9.0058215e-08\n",
      "5.7\t3.8\t1.7\t0.3\t1.0\t0.0\t0.0\t0.8867043\t0.11329559\t1.6179845e-08\n",
      "5.1\t3.8\t1.5\t0.3\t1.0\t0.0\t0.0\t0.89768225\t0.102317736\t4.9852655e-08\n",
      "5.4\t3.4\t1.7\t0.2\t1.0\t0.0\t0.0\t0.833366\t0.16663393\t5.601651e-08\n",
      "5.1\t3.7\t1.5\t0.4\t1.0\t0.0\t0.0\t0.89659154\t0.10340849\t5.140392e-08\n",
      "4.6\t3.6\t1.0\t0.2\t1.0\t0.0\t0.0\t0.91697526\t0.08302435\t2.7969014e-07\n",
      "5.1\t3.3\t1.7\t0.5\t1.0\t0.0\t0.0\t0.84340924\t0.15659063\t7.0592584e-08\n",
      "4.8\t3.4\t1.9\t0.2\t1.0\t0.0\t0.0\t0.7830079\t0.216992\t1.13342246e-07\n",
      "5.0\t3.0\t1.6\t0.2\t1.0\t0.0\t0.0\t0.789815\t0.21018481\t2.1653418e-07\n",
      "5.0\t3.4\t1.6\t0.4\t1.0\t0.0\t0.0\t0.8566953\t0.14330456\t8.857464e-08\n",
      "5.2\t3.5\t1.5\t0.2\t1.0\t0.0\t0.0\t0.86714417\t0.13285573\t7.972069e-08\n",
      "5.2\t3.4\t1.4\t0.2\t1.0\t0.0\t0.0\t0.8704305\t0.12956932\t1.0374544e-07\n",
      "4.7\t3.2\t1.6\t0.2\t1.0\t0.0\t0.0\t0.8074326\t0.19256705\t2.5051835e-07\n",
      "4.8\t3.1\t1.6\t0.2\t1.0\t0.0\t0.0\t0.7973432\t0.20265645\t2.514974e-07\n",
      "5.4\t3.4\t1.5\t0.4\t1.0\t0.0\t0.0\t0.87750214\t0.12249777\t5.2858603e-08\n",
      "5.2\t4.1\t1.5\t0.1\t1.0\t0.0\t0.0\t0.90841025\t0.091589764\t3.4035715e-08\n",
      "5.5\t4.2\t1.4\t0.2\t1.0\t0.0\t0.0\t0.9314002\t0.068599865\t1.736424e-08\n",
      "4.9\t3.1\t1.5\t0.2\t1.0\t0.0\t0.0\t0.8172171\t0.18278265\t2.402918e-07\n",
      "5.0\t3.2\t1.2\t0.2\t1.0\t0.0\t0.0\t0.8729247\t0.12707512\t2.3922445e-07\n",
      "5.5\t3.5\t1.3\t0.2\t1.0\t0.0\t0.0\t0.8956024\t0.104397506\t6.117564e-08\n",
      "4.9\t3.6\t1.4\t0.1\t1.0\t0.0\t0.0\t0.87488633\t0.12511352\t1.3591911e-07\n",
      "4.4\t3.0\t1.3\t0.2\t1.0\t0.0\t0.0\t0.82465106\t0.17534818\t7.502348e-07\n",
      "5.1\t3.4\t1.5\t0.2\t1.0\t0.0\t0.0\t0.85531825\t0.14468166\t1.0935747e-07\n",
      "5.0\t3.5\t1.3\t0.3\t1.0\t0.0\t0.0\t0.8938219\t0.10617794\t1.1602902e-07\n",
      "4.5\t2.3\t1.3\t0.3\t1.0\t0.0\t0.0\t0.7438551\t0.25614327\t1.6880975e-06\n",
      "4.4\t3.2\t1.3\t0.2\t1.0\t0.0\t0.0\t0.84694386\t0.15305561\t5.449855e-07\n",
      "5.0\t3.5\t1.6\t0.6\t1.0\t0.0\t0.0\t0.8816802\t0.118319675\t5.7792576e-08\n",
      "5.1\t3.8\t1.9\t0.4\t1.0\t0.0\t0.0\t0.85822475\t0.14177522\t2.9280612e-08\n",
      "4.8\t3.0\t1.4\t0.3\t1.0\t0.0\t0.0\t0.8289577\t0.171042\t3.2089906e-07\n",
      "5.1\t3.8\t1.6\t0.2\t1.0\t0.0\t0.0\t0.8799626\t0.120037325\t5.162222e-08\n",
      "4.6\t3.2\t1.4\t0.2\t1.0\t0.0\t0.0\t0.83699524\t0.16300441\t3.610867e-07\n",
      "5.3\t3.7\t1.5\t0.2\t1.0\t0.0\t0.0\t0.8865795\t0.1134205\t4.9289905e-08\n",
      "5.0\t3.3\t1.4\t0.2\t1.0\t0.0\t0.0\t0.85669243\t0.14330734\t1.6608988e-07\n",
      "7.0\t3.2\t4.7\t1.4\t0.0\t1.0\t0.0\t0.3228638\t0.67713624\t3.429108e-11\n",
      "6.4\t3.2\t4.5\t1.5\t0.0\t1.0\t0.0\t0.3642611\t0.6357389\t1.0223075e-10\n",
      "6.9\t3.1\t4.9\t1.5\t0.0\t1.0\t0.0\t0.2708233\t0.7291767\t2.921554e-11\n",
      "5.5\t2.3\t4.0\t1.3\t0.0\t1.0\t0.0\t0.26188555\t0.7381145\t2.9238554e-09\n",
      "6.5\t2.8\t4.6\t1.5\t0.0\t1.0\t0.0\t0.27394837\t0.7260516\t1.2051238e-10\n",
      "5.7\t2.8\t4.5\t1.3\t0.0\t1.0\t0.0\t0.24140704\t0.758593\t5.3794413e-10\n",
      "6.3\t3.3\t4.7\t1.6\t0.0\t1.0\t0.0\t0.3443252\t0.65567476\t6.942384e-11\n",
      "4.9\t2.4\t3.3\t1.0\t0.0\t1.0\t0.0\t0.37791938\t0.6220806\t2.5426246e-08\n",
      "6.6\t2.9\t4.6\t1.3\t0.0\t1.0\t0.0\t0.2660642\t0.7339358\t1.116435e-10\n",
      "5.2\t2.7\t3.9\t1.4\t0.0\t1.0\t0.0\t0.3579472\t0.6420528\t3.028258e-09\n",
      "5.0\t2.0\t3.5\t1.0\t0.0\t1.0\t0.0\t0.26380068\t0.73619926\t2.5515074e-08\n",
      "5.9\t3.0\t4.2\t1.5\t0.0\t1.0\t0.0\t0.38284102\t0.617159\t4.3098994e-10\n",
      "6.0\t2.2\t4.0\t1.0\t0.0\t1.0\t0.0\t0.2248506\t0.7751494\t2.0835738e-09\n",
      "6.1\t2.9\t4.7\t1.4\t0.0\t1.0\t0.0\t0.24163474\t0.7583653\t1.7672701e-10\n",
      "5.6\t2.9\t3.6\t1.3\t0.0\t1.0\t0.0\t0.47752544\t0.52247447\t2.2794626e-09\n",
      "6.7\t3.1\t4.4\t1.4\t0.0\t1.0\t0.0\t0.36713025\t0.63286966\t9.615611e-11\n",
      "5.6\t3.0\t4.5\t1.5\t0.0\t1.0\t0.0\t0.29712853\t0.7028715\t4.1290737e-10\n",
      "5.8\t2.7\t4.1\t1.0\t0.0\t1.0\t0.0\t0.27358297\t0.72641695\t1.3382623e-09\n",
      "6.2\t2.2\t4.5\t1.5\t0.0\t1.0\t0.0\t0.19694336\t0.80305666\t4.2714868e-10\n",
      "5.6\t2.5\t3.9\t1.1\t0.0\t1.0\t0.0\t0.2922012\t0.70779884\t2.8534284e-09\n",
      "5.9\t3.2\t4.8\t1.8\t0.0\t1.0\t0.0\t0.31706962\t0.68293035\t9.835216e-11\n",
      "6.1\t2.8\t4.0\t1.3\t0.0\t1.0\t0.0\t0.37203622\t0.6279638\t6.826222e-10\n",
      "6.3\t2.5\t4.9\t1.5\t0.0\t1.0\t0.0\t0.17016299\t0.82983696\t1.3281294e-10\n",
      "6.1\t2.8\t4.7\t1.2\t0.0\t1.0\t0.0\t0.20358008\t0.7964199\t2.3485555e-10\n",
      "6.4\t2.9\t4.3\t1.3\t0.0\t1.0\t0.0\t0.3274842\t0.67251575\t2.436632e-10\n",
      "6.6\t3.0\t4.4\t1.4\t0.0\t1.0\t0.0\t0.3444442\t0.65555584\t1.2546335e-10\n",
      "6.8\t2.8\t4.8\t1.4\t0.0\t1.0\t0.0\t0.2294447\t0.7705553\t6.1116986e-11\n",
      "6.7\t3.0\t5.0\t1.7\t0.0\t1.0\t0.0\t0.25383145\t0.7461686\t3.079486e-11\n",
      "6.0\t2.9\t4.5\t1.5\t0.0\t1.0\t0.0\t0.2949196\t0.7050804\t2.603991e-10\n",
      "5.7\t2.6\t3.5\t1.0\t0.0\t1.0\t0.0\t0.39780882\t0.60219115\t4.54679e-09\n",
      "5.5\t2.4\t3.8\t1.1\t0.0\t1.0\t0.0\t0.29451254\t0.70548743\t4.360996e-09\n",
      "5.5\t2.4\t3.7\t1.0\t0.0\t1.0\t0.0\t0.30302852\t0.6969715\t5.634866e-09\n",
      "5.8\t2.7\t3.9\t1.2\t0.0\t1.0\t0.0\t0.35041708\t0.649583\t1.5361231e-09\n",
      "6.0\t2.7\t5.1\t1.6\t0.0\t1.0\t0.0\t0.16442409\t0.8355759\t1.0607151e-10\n",
      "5.4\t3.0\t4.5\t1.5\t0.0\t1.0\t0.0\t0.2897969\t0.7102031\t5.509195e-10\n",
      "6.0\t3.4\t4.5\t1.6\t0.0\t1.0\t0.0\t0.40239614\t0.59760386\t1.2978847e-10\n",
      "6.7\t3.1\t4.7\t1.5\t0.0\t1.0\t0.0\t0.30884933\t0.69115067\t5.4184338e-11\n",
      "6.3\t2.3\t4.4\t1.3\t0.0\t1.0\t0.0\t0.20827442\t0.7917256\t4.697987e-10\n",
      "5.6\t3.0\t4.1\t1.3\t0.0\t1.0\t0.0\t0.36368573\t0.6363142\t9.475098e-10\n",
      "5.5\t2.5\t4.0\t1.3\t0.0\t1.0\t0.0\t0.29451716\t0.70548284\t2.325725e-09\n",
      "5.5\t2.6\t4.4\t1.2\t0.0\t1.0\t0.0\t0.21377173\t0.78622824\t1.1570108e-09\n",
      "6.1\t3.0\t4.6\t1.4\t0.0\t1.0\t0.0\t0.27843016\t0.72156984\t1.8673106e-10\n",
      "5.8\t2.6\t4.0\t1.2\t0.0\t1.0\t0.0\t0.30817127\t0.6918288\t1.4732439e-09\n",
      "5.0\t2.3\t3.3\t1.0\t0.0\t1.0\t0.0\t0.36307764\t0.6369224\t2.4833493e-08\n",
      "5.6\t2.7\t4.2\t1.3\t0.0\t1.0\t0.0\t0.2862791\t0.71372086\t1.1499692e-09\n",
      "5.7\t3.0\t4.2\t1.2\t0.0\t1.0\t0.0\t0.32708967\t0.67291033\t7.696401e-10\n",
      "5.7\t2.9\t4.2\t1.3\t0.0\t1.0\t0.0\t0.32449338\t0.6755066\t7.8824774e-10\n",
      "6.2\t2.9\t4.3\t1.3\t0.0\t1.0\t0.0\t0.3197442\t0.6802558\t3.2545322e-10\n",
      "5.1\t2.5\t3.0\t1.1\t0.0\t1.0\t0.0\t0.5045646\t0.4954354\t2.3486692e-08\n",
      "5.7\t2.8\t4.1\t1.3\t0.0\t1.0\t0.0\t0.33084458\t0.6691554\t1.0419234e-09\n",
      "6.3\t3.3\t6.0\t2.5\t0.0\t0.0\t1.0\t0.18991797\t0.810082\t3.488322e-12\n",
      "5.8\t2.7\t5.1\t1.9\t0.0\t0.0\t1.0\t0.18961342\t0.8103866\t1.0952205e-10\n",
      "7.1\t3.0\t5.9\t2.1\t0.0\t0.0\t1.0\t0.151752\t0.848248\t2.5670937e-12\n",
      "6.3\t2.9\t5.6\t1.8\t0.0\t0.0\t1.0\t0.13922478\t0.8607753\t1.9423161e-11\n",
      "6.5\t3.0\t5.8\t2.2\t0.0\t0.0\t1.0\t0.16146693\t0.8385331\t6.619757e-12\n",
      "7.6\t3.0\t6.6\t2.1\t0.0\t0.0\t1.0\t0.08289901\t0.91710097\t3.4974324e-13\n",
      "4.9\t2.5\t4.5\t1.7\t0.0\t0.0\t1.0\t0.22228777\t0.7777122\t1.6572663e-09\n",
      "7.3\t2.9\t6.3\t1.8\t0.0\t0.0\t1.0\t0.081960015\t0.91804\t1.3028179e-12\n",
      "6.7\t2.5\t5.8\t1.8\t0.0\t0.0\t1.0\t0.09140326\t0.9085967\t1.1457098e-11\n",
      "7.2\t3.6\t6.1\t2.5\t0.0\t0.0\t1.0\t0.23910359\t0.76089644\t5.8492577e-13\n",
      "6.5\t3.2\t5.1\t2.0\t0.0\t0.0\t1.0\t0.29887924\t0.70112073\t2.1060792e-11\n",
      "6.4\t2.7\t5.3\t1.9\t0.0\t0.0\t1.0\t0.17268069\t0.82731926\t3.277227e-11\n",
      "6.8\t3.0\t5.5\t2.1\t0.0\t0.0\t1.0\t0.20860507\t0.791395\t7.979658e-12\n",
      "5.7\t2.5\t5.0\t2.0\t0.0\t0.0\t1.0\t0.18951038\t0.8104896\t1.7135608e-10\n",
      "5.8\t2.8\t5.1\t2.4\t0.0\t0.0\t1.0\t0.26431018\t0.7356899\t6.334866e-11\n",
      "6.4\t3.2\t5.3\t2.3\t0.0\t0.0\t1.0\t0.29273894\t0.707261\t1.3283221e-11\n",
      "6.5\t3.0\t5.5\t1.8\t0.0\t0.0\t1.0\t0.16869473\t0.8313052\t1.5775313e-11\n",
      "7.7\t3.8\t6.7\t2.2\t0.0\t0.0\t1.0\t0.14480029\t0.85519975\t1.0409334e-13\n",
      "7.7\t2.6\t6.9\t2.3\t0.0\t0.0\t1.0\t0.05202223\t0.9479778\t2.1814565e-13\n",
      "6.0\t2.2\t5.0\t1.5\t0.0\t0.0\t1.0\t0.12008376\t0.8799163\t2.312209e-10\n",
      "6.9\t3.2\t5.7\t2.3\t0.0\t0.0\t1.0\t0.22542486\t0.7745752\t3.3066293e-12\n",
      "5.6\t2.8\t4.9\t2.0\t0.0\t0.0\t1.0\t0.24661401\t0.753386\t1.6915637e-10\n",
      "7.7\t2.8\t6.7\t2.0\t0.0\t0.0\t1.0\t0.061328776\t0.93867123\t3.3038803e-13\n",
      "6.3\t2.7\t4.9\t1.8\t0.0\t0.0\t1.0\t0.2291146\t0.77088535\t8.2783676e-11\n",
      "6.7\t3.3\t5.7\t2.1\t0.0\t0.0\t1.0\t0.20959428\t0.7904057\t4.6921993e-12\n",
      "7.2\t3.2\t6.0\t1.8\t0.0\t0.0\t1.0\t0.1347892\t0.8652108\t1.9322079e-12\n",
      "6.2\t2.8\t4.8\t1.8\t0.0\t0.0\t1.0\t0.26124227\t0.7387577\t1.0123642e-10\n",
      "6.1\t3.0\t4.9\t1.8\t0.0\t0.0\t1.0\t0.2680165\t0.73198354\t7.880335e-11\n",
      "6.4\t2.8\t5.6\t2.1\t0.0\t0.0\t1.0\t0.15750949\t0.8424905\t1.4621072e-11\n",
      "7.2\t3.0\t5.8\t1.6\t0.0\t0.0\t1.0\t0.12558118\t0.87441885\t4.013795e-12\n",
      "7.4\t2.8\t6.1\t1.9\t0.0\t0.0\t1.0\t0.10066642\t0.8993336\t1.6790834e-12\n",
      "7.9\t3.8\t6.4\t2.0\t0.0\t0.0\t1.0\t0.17520699\t0.82479304\t1.5831082e-13\n",
      "6.4\t2.8\t5.6\t2.2\t0.0\t0.0\t1.0\t0.1669536\t0.8330465\t1.3455689e-11\n",
      "6.3\t2.8\t5.1\t1.5\t0.0\t0.0\t1.0\t0.1735305\t0.82646954\t6.777099e-11\n",
      "6.1\t2.6\t5.6\t1.4\t0.0\t0.0\t1.0\t0.08478138\t0.9152186\t4.7866763e-11\n",
      "7.7\t3.0\t6.1\t2.3\t0.0\t0.0\t1.0\t0.15496998\t0.84503\t6.4932326e-13\n",
      "6.3\t3.4\t5.6\t2.4\t0.0\t0.0\t1.0\t0.26931316\t0.73068684\t6.7716974e-12\n",
      "6.4\t3.1\t5.5\t1.8\t0.0\t0.0\t1.0\t0.17780884\t0.8221911\t1.6355873e-11\n",
      "6.0\t3.0\t4.8\t1.8\t0.0\t0.0\t1.0\t0.2865423\t0.7134577\t1.0744117e-10\n",
      "6.9\t3.1\t5.4\t2.1\t0.0\t0.0\t1.0\t0.24523357\t0.7547664\t7.354523e-12\n",
      "6.7\t3.1\t5.6\t2.4\t0.0\t0.0\t1.0\t0.23660997\t0.76339006\t5.344357e-12\n",
      "6.9\t3.1\t5.1\t2.3\t0.0\t0.0\t1.0\t0.34192425\t0.6580758\t1.0019561e-11\n",
      "5.8\t2.7\t5.1\t1.9\t0.0\t0.0\t1.0\t0.18961342\t0.8103866\t1.0952205e-10\n",
      "6.8\t3.2\t5.9\t2.3\t0.0\t0.0\t1.0\t0.18659094\t0.8134091\t2.6928065e-12\n",
      "6.7\t3.3\t5.7\t2.5\t0.0\t0.0\t1.0\t0.25934795\t0.740652\t3.299368e-12\n",
      "6.7\t3.0\t5.2\t2.3\t0.0\t0.0\t1.0\t0.29285282\t0.7071471\t1.2802536e-11\n",
      "6.3\t2.5\t5.0\t1.9\t0.0\t0.0\t1.0\t0.19519311\t0.80480695\t7.9402596e-11\n",
      "6.5\t3.0\t5.2\t2.0\t0.0\t0.0\t1.0\t0.24500364\t0.7549964\t2.2386773e-11\n",
      "6.2\t3.4\t5.4\t2.3\t0.0\t0.0\t1.0\t0.29629838\t0.7037017\t1.1931255e-11\n",
      "5.9\t3.0\t5.1\t1.8\t0.0\t0.0\t1.0\t0.22090891\t0.7790911\t7.4742955e-11\n"
     ]
    }
   ],
   "source": [
    "for di in range(0, len(iris.data)):\n",
    "    print(\n",
    "        str(iris.data[di][0])+\"\\t\"+\n",
    "        str(iris.data[di][1])+\"\\t\"+\n",
    "        str(iris.data[di][2])+\"\\t\"+\n",
    "        str(iris.data[di][3])+\"\\t\"+\n",
    "        str(targets[di][0])+\"\\t\"+\n",
    "        str(targets[di][1])+\"\\t\"+\n",
    "        str(targets[di][2])+\"\\t\"+\n",
    "        str(predictions[di][0])+\"\\t\"+\n",
    "        str(predictions[di][1])+\"\\t\"+\n",
    "        str(predictions[di][2])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
